import OpenAI from 'openai';
import fs from 'fs/promises';
import path from 'path';
import xlsx from 'xlsx';
import type { CashFlowAnalysis, Transaction, OpenAIAnalysisResult } from '../types.js';

// Configure OpenAI client
// Set USE_OPENROUTER=true to use OpenRouter, otherwise uses OpenAI directly
const USE_OPENROUTER = process.env.USE_OPENROUTER === 'true';

const openai = USE_OPENROUTER
  ? new OpenAI({
      apiKey: process.env.OPENROUTER_API_KEY,
      baseURL: 'https://openrouter.ai/api/v1',
      defaultHeaders: {
        'HTTP-Referer': process.env.YOUR_SITE_URL || 'https://aio-simulator.cmgfinancial.ai',
        'X-Title': 'All-In-One Look Back Simulator',
      },
    })
  : new OpenAI({
      apiKey: process.env.OPENAI_API_KEY, // Direct OpenAI API key
    });

// Model selection based on provider
const VISION_MODEL = USE_OPENROUTER
  ? 'google/gemini-2.0-flash-exp' // Gemini 2.0 Flash via OpenRouter - fast vision + document processing
  : 'gpt-4o'; // GPT-4o via OpenAI Direct - proven vision + PDF support, no 8k limit

console.log(`üîß AI Provider: ${USE_OPENROUTER ? 'OpenRouter' : 'OpenAI Direct'}`);
console.log(`ü§ñ Vision Model: ${VISION_MODEL}`);

/**
 * Note: PDFs are now processed NATIVELY using Gemini 2.0 Flash's PDF capabilities.
 * This eliminates the need for client-side PDF-to-image conversion.
 * The analyzePdf function handles direct PDF analysis.
 */

/**
 * Extract data from Excel/CSV file with intelligent compression
 *
 * OPTIMIZATION: Extract only essential fields and limit to recent months
 * to dramatically reduce token usage while maintaining analysis quality
 */
async function extractDataFromSpreadsheet(filePath: string): Promise<string> {
  try {
    const workbook = xlsx.readFile(filePath);
    const sheetName = workbook.SheetNames[0];
    const worksheet = workbook.Sheets[sheetName];
    const jsonData = xlsx.utils.sheet_to_json(worksheet);

    console.log(`Original spreadsheet has ${jsonData.length} rows`);

    // Compress data: Extract only essential fields
    const compressedData = jsonData.map((row: any) => {
      // Try common field names for date, description, amount
      const date = row['Posting Date'] || row['Date'] || row['Transaction Date'] || row['date'];
      const description = row['Description'] || row['Merchant'] || row['description'] || row['memo'];
      const amount = row['Amount'] || row['amount'] || row['Debit'] || row['Credit'];
      const type = row['Type'] || row['Transaction Type'] || row['Category'];

      return { date, description, amount, type };
    }).filter(row => row.date && row.amount); // Filter out invalid rows

    // Sort by date (newest first) and limit to recent 6 months (180 days)
    const sixMonthsAgo = new Date();
    sixMonthsAgo.setMonth(sixMonthsAgo.getMonth() - 6);

    const recentData = compressedData.filter((row: any) => {
      try {
        const transactionDate = new Date(row.date);
        return transactionDate >= sixMonthsAgo;
      } catch {
        return true; // Keep if date parsing fails (let AI handle it)
      }
    });

    console.log(`Filtered to ${recentData.length} recent transactions (last 6 months)`);
    console.log(`Data reduction: ${jsonData.length} ‚Üí ${recentData.length} rows (${((1 - recentData.length/jsonData.length) * 100).toFixed(1)}% reduction)`);

    return JSON.stringify(recentData);
  } catch (error) {
    console.error('Error extracting spreadsheet data:', error);
    throw new Error('Failed to extract data from spreadsheet');
  }
}

/**
 * Analyze image file using vision model via OpenRouter
 * Supports images from various sources including client-side PDF conversions
 */
async function analyzeImage(filePath: string): Promise<string> {
  const TIMEOUT_MS = 60000; // 60 seconds

  try {
    console.log('üîç [1/5] Starting image analysis...');
    console.log(`   üìÅ File: ${filePath}`);

    console.log('üìñ [2/5] Reading image file...');
    const imageBuffer = await fs.readFile(filePath);
    console.log(`   ‚úì File read successfully (${imageBuffer.length} bytes)`);

    console.log('üîÑ [3/5] Converting to base64...');
    const base64Image = imageBuffer.toString('base64');
    const ext = path.extname(filePath).toLowerCase();
    const mimeType = ext === '.png' ? 'image/png' : 'image/jpeg';
    console.log(`   ‚úì Converted to base64 (${base64Image.length} chars, type: ${mimeType})`);

    console.log('üåê [4/5] Calling AI API...');
    console.log(`   üì° Endpoint: ${openai.baseURL || 'https://api.openai.com/v1'}`);
    console.log(`   ü§ñ Model: ${VISION_MODEL}`);
    console.log(`   ‚è±Ô∏è  Timeout: ${TIMEOUT_MS / 1000}s`);

    // Create a timeout promise that rejects after TIMEOUT_MS
    const timeoutPromise = new Promise<never>((_, reject) => {
      setTimeout(() => {
        console.error(`‚è±Ô∏è  ‚ùå TIMEOUT FIRED - No response after ${TIMEOUT_MS / 1000}s`);
        reject(new Error(`Image analysis timed out after ${TIMEOUT_MS / 1000} seconds`));
      }, TIMEOUT_MS);
    });

    console.log('   üöÄ Sending API request NOW...');
    const startTime = Date.now();

    // Create the API call promise using configured model
    // GPT-5 has native PDF support, Claude has excellent vision capabilities
    const apiCallPromise = openai.chat.completions.create({
      model: VISION_MODEL,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: `Extract ALL transaction data from this bank statement image.

For each transaction, provide:
- Date (YYYY-MM-DD format)
- Description
- Amount (positive for deposits, negative for withdrawals)

Include:
- All deposits (income, paychecks, transfers in)
- All withdrawals (purchases, payments, transfers out)
- Account balance information if visible

Format each transaction on a new line like:
2024-08-15 | Paycheck Deposit | +3500.00
2024-08-16 | Grocery Store | -125.50

Be thorough and extract EVERY transaction visible in the image.`,
            },
            {
              type: 'image_url',
              image_url: {
                url: `data:${mimeType};base64,${base64Image}`,
              },
            },
          ],
        },
      ],
      max_tokens: 4096, // GPT-4o uses max_tokens
    }, {
      timeout: TIMEOUT_MS, // SDK timeout as backup
    });

    console.log('   ‚è≥ Waiting for response...');
    // Race the API call against the timeout
    const response = await Promise.race([apiCallPromise, timeoutPromise]);

    const elapsedTime = Date.now() - startTime;
    console.log(`‚úÖ [5/5] API response received in ${(elapsedTime / 1000).toFixed(2)}s`);
    console.log(`   üìù Response length: ${response.choices[0]?.message?.content?.length || 0} chars`);

    return response.choices[0]?.message?.content || '';
  } catch (error) {
    console.error('‚ùå Error analyzing image:', error);

    // Provide more specific error messages
    if (error instanceof Error) {
      if (error.message.includes('timeout') || error.message.includes('timed out')) {
        throw new Error(`Image analysis timed out after ${TIMEOUT_MS / 1000} seconds. Please try again or use a smaller image.`);
      }
      throw new Error(`Failed to analyze image: ${error.message}`);
    }
    throw new Error('Failed to analyze image with vision model');
  }
}

/**
 * Analyze PDF file using vision model via OpenAI
 * TESTING: Native PDF support (no conversion to images)
 */
async function analyzePdf(filePath: string): Promise<string> {
  const TIMEOUT_MS = 120000; // 120 seconds for PDFs (can be multi-page)

  try {
    console.log('üìÑ [1/4] Starting PDF analysis...');
    console.log(`   üìÅ File: ${filePath}`);

    console.log('üìñ [2/4] Reading PDF file...');
    const pdfBuffer = await fs.readFile(filePath);
    console.log(`   ‚úì File read successfully (${pdfBuffer.length} bytes)`);

    console.log('üîÑ [3/4] Converting to base64...');
    const base64Pdf = pdfBuffer.toString('base64');
    console.log(`   ‚úì Converted to base64 (${base64Pdf.length} chars)`);

    console.log('üåê [4/4] Calling AI API with native PDF...');
    console.log(`   üì° Endpoint: ${openai.baseURL || 'https://api.openai.com/v1'}`);
    console.log(`   ü§ñ Model: ${VISION_MODEL}`);
    console.log(`   ‚è±Ô∏è  Timeout: ${TIMEOUT_MS / 1000}s`);

    const timeoutPromise = new Promise<never>((_, reject) => {
      setTimeout(() => {
        console.error(`‚è±Ô∏è  ‚ùå TIMEOUT FIRED - No response after ${TIMEOUT_MS / 1000}s`);
        reject(new Error(`PDF analysis timed out after ${TIMEOUT_MS / 1000} seconds`));
      }, TIMEOUT_MS);
    });

    console.log('   üöÄ Sending API request NOW with native PDF...');
    const startTime = Date.now();

    // Send PDF directly to OpenAI using file input format
    const apiCallPromise = openai.chat.completions.create({
      model: VISION_MODEL,
      messages: [
        {
          role: 'user',
          content: [
            {
              type: 'text',
              text: `Extract ALL transaction data from this bank statement PDF.

For each transaction, provide:
- Date (YYYY-MM-DD format)
- Description
- Amount (positive for deposits, negative for withdrawals)

Include:
- All deposits (income, paychecks, transfers in)
- All withdrawals (purchases, payments, transfers out)
- Account balance information if visible

Format each transaction on a new line like:
2024-08-15 | Paycheck Deposit | +3500.00
2024-08-16 | Grocery Store | -125.50

Be thorough and extract EVERY transaction visible in the PDF.`,
            },
            {
              type: 'image_url',
              image_url: {
                url: `data:application/pdf;base64,${base64Pdf}`,
              },
            },
          ],
        },
      ],
      max_tokens: 16000, // Higher limit for multi-page PDFs
    }, {
      timeout: TIMEOUT_MS,
    });

    console.log('   ‚è≥ Waiting for response...');
    const response = await Promise.race([apiCallPromise, timeoutPromise]);

    const elapsedTime = Date.now() - startTime;
    console.log(`‚úÖ [4/4] API response received in ${(elapsedTime / 1000).toFixed(2)}s`);
    console.log(`   üìù Response length: ${response.choices[0]?.message?.content?.length || 0} chars`);

    return response.choices[0]?.message?.content || '';
  } catch (error) {
    console.error('‚ùå Error analyzing PDF:', error);

    if (error instanceof Error) {
      if (error.message.includes('timeout') || error.message.includes('timed out')) {
        throw new Error(`PDF analysis timed out after ${TIMEOUT_MS / 1000} seconds. Please try again.`);
      }
      throw new Error(`Failed to analyze PDF: ${error.message}`);
    }
    throw new Error('Failed to analyze PDF with vision model');
  }
}

/**
 * Estimate token count (rough approximation: 1 token ‚âà 4 characters)
 */
function estimateTokens(text: string): number {
  return Math.ceil(text.length / 4);
}

/**
 * Split large data into chunks to stay under token limits
 *
 * OPTIMIZATION: Process data in smaller batches to avoid rate limits
 * Each chunk stays under 15K tokens to safely fit within 30K TPM limit
 */
function chunkData(data: string, maxTokensPerChunk: number = 15000): string[] {
  const estimatedTokens = estimateTokens(data);

  if (estimatedTokens <= maxTokensPerChunk) {
    console.log(`Data fits in single chunk (${estimatedTokens} tokens)`);
    return [data];
  }

  console.log(`Data too large (${estimatedTokens} tokens), splitting into chunks...`);

  try {
    // Parse JSON array
    const transactions = JSON.parse(data);

    if (!Array.isArray(transactions)) {
      console.log('Data is not an array, returning as single chunk');
      return [data];
    }

    // Calculate transactions per chunk
    const avgCharsPerTransaction = data.length / transactions.length;
    const avgTokensPerTransaction = avgCharsPerTransaction / 4;
    const transactionsPerChunk = Math.floor(maxTokensPerChunk / avgTokensPerTransaction);

    console.log(`Splitting ${transactions.length} transactions into chunks of ~${transactionsPerChunk} each`);

    const chunks: string[] = [];
    for (let i = 0; i < transactions.length; i += transactionsPerChunk) {
      const chunk = transactions.slice(i, i + transactionsPerChunk);
      chunks.push(JSON.stringify(chunk));
      console.log(`Chunk ${chunks.length}: ${chunk.length} transactions (~${estimateTokens(JSON.stringify(chunk))} tokens)`);
    }

    return chunks;
  } catch (error) {
    console.error('Error chunking data:', error);
    // If parsing fails, return original data as single chunk
    return [data];
  }
}

/**
 * Process a single bank statement file with retry logic
 * Supports native PDF processing via Gemini 2.0 Flash
 */
async function processFile(file: Express.Multer.File, retries = 2): Promise<string> {
  const ext = path.extname(file.originalname).toLowerCase();

  if (ext === '.csv' || ext === '.xlsx' || ext === '.xls') {
    return await extractDataFromSpreadsheet(file.path);
  } else if (ext === '.pdf') {
    // Retry logic for PDF analysis with native PDF support
    let lastError: Error | null = null;
    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        console.log(`Attempt ${attempt}/${retries} for PDF ${file.originalname}`);
        return await analyzePdf(file.path);
      } catch (error) {
        lastError = error as Error;
        console.error(`Attempt ${attempt}/${retries} failed:`, error instanceof Error ? error.message : error);
        if (attempt < retries) {
          console.log(`Retrying in 2 seconds...`);
          await new Promise(resolve => setTimeout(resolve, 2000));
        }
      }
    }
    throw lastError || new Error('Failed to process PDF after retries');
  } else if (['.jpg', '.jpeg', '.png', '.gif', '.webp'].includes(ext)) {
    // Retry logic for image analysis
    let lastError: Error | null = null;
    for (let attempt = 1; attempt <= retries; attempt++) {
      try {
        console.log(`Attempt ${attempt}/${retries} for ${file.originalname}`);
        return await analyzeImage(file.path);
      } catch (error) {
        lastError = error as Error;
        console.error(`Attempt ${attempt}/${retries} failed:`, error instanceof Error ? error.message : error);
        if (attempt < retries) {
          console.log(`Retrying in 2 seconds...`);
          await new Promise(resolve => setTimeout(resolve, 2000));
        }
      }
    }
    throw lastError || new Error('Failed to process image after retries');
  } else {
    throw new Error(`Unsupported file type: ${ext}`);
  }
}

/**
 * Analyze bank statements using OpenAI GPT-4
 */
export async function analyzeStatements(
  files: Express.Multer.File[],
  currentHousingPayment: number
): Promise<CashFlowAnalysis> {
  try {
    console.log(`Processing ${files.length} files...`);

    // Extract text/data from all files, with error handling for individual files
    const extractedData: string[] = [];
    const failedFiles: string[] = [];

    for (const file of files) {
      console.log(`Processing file: ${file.originalname}`);
      try {
        const content = await processFile(file);
        extractedData.push(content);
        console.log(`‚úì Successfully processed ${file.originalname}`);
      } catch (error) {
        console.error(`‚úó Failed to process ${file.originalname}:`, error instanceof Error ? error.message : error);
        failedFiles.push(file.originalname);
        // Continue processing other files instead of failing completely
      }
    }

    if (extractedData.length === 0) {
      throw new Error(`Failed to process any files. ${failedFiles.length} file(s) failed: ${failedFiles.join(', ')}`);
    }

    if (failedFiles.length > 0) {
      console.log(`‚ö†Ô∏è  Warning: ${failedFiles.length} file(s) failed to process: ${failedFiles.join(', ')}`);
      console.log(`‚úì Successfully processed ${extractedData.length} file(s), continuing with analysis...`);
    }

    const combinedData = extractedData.join('\n\n---NEW DOCUMENT---\n\n');

    console.log('üîç Analyzing combined transaction data with AI...');
    console.log(`üìä Combined data length: ${combinedData.length} characters (~${estimateTokens(combinedData)} tokens)`);

    // Check if data needs chunking
    const chunks = chunkData(combinedData, 12000); // Conservative 12K tokens per chunk (leaves room for prompt)

    // For chunked data, process the first chunk for now (simplified approach)
    // Future enhancement: Process all chunks and merge results
    const dataToAnalyze = chunks.length > 1
      ? `${chunks[0]}\n\n[NOTE: This is chunk 1 of ${chunks.length}. Analysis is based on recent transactions.]`
      : combinedData;

    console.log(chunks.length > 1
      ? `‚ö†Ô∏è  Using first chunk only (${chunks.length} chunks total). Recent transactions prioritized.`
      : `‚úì Processing all data in single request`);

    // Use GPT-4 to analyze the transactions with enhanced anomaly detection
    const prompt = `You are a financial analysis expert. Analyze the following bank statement data covering multiple months of transactions.

Current housing payment (to exclude): $${currentHousingPayment}

Bank Statement Data:
${dataToAnalyze}

Please perform a COMPREHENSIVE analysis with the following objectives:

1. **EXTRACT & CATEGORIZE ALL TRANSACTIONS**:
   - "income": Regular income deposits (salary, wages, business income)
   - "expense": Regular recurring monthly expenses (groceries, utilities, insurance, subscriptions, etc.)
   - "housing": Current rent/mortgage payments (around $${currentHousingPayment})
   - "one-time": One-time or irregular transactions

2. **IDENTIFY ANOMALIES & FLAG FOR REVIEW**:
   Flag transactions that are:
   - **Luxury items**: High-end dining, designer purchases, jewelry, luxury travel
   - **Unusually large**: 2x or more above typical spending in that category
   - **One-time purchases**: Major purchases, large cash withdrawals, large deposits
   - **Irregular deposits**: Tax refunds, bonuses, gifts, large transfers
   - **Non-essential**: Entertainment, hobbies, discretionary spending above normal patterns

   For each flagged transaction, provide a specific reason (e.g., "Luxury dining - $500 at upscale restaurant", "One-time: New laptop purchase", "Irregular: Large tax refund")

3. **MONTHLY BREAKDOWN**:
   Provide month-by-month summary showing:
   - Total income per month
   - Total expenses per month (excluding housing and flagged items)
   - Net cash flow per month
   - Transaction count per month

4. **CALCULATE AVERAGES**:
   - Average monthly income
   - Average monthly expenses (EXCLUDING housing and flagged one-time items)
   - Average net monthly cash flow (available to offset mortgage principal)

5. **CONFIDENCE SCORE**: Your confidence in the analysis (0-1 scale)

CRITICAL RULES:
- EXCLUDE current housing payments ($${currentHousingPayment}) from expense calculations
- FLAG any transaction that seems irregular, luxury, or one-time
- Only include predictable recurring expenses in the final average
- Look back at as much historical data as possible
- Be conservative: when in doubt, flag it for user review

Return your response in the following JSON format:
{
  "transactions": [
    {
      "date": "YYYY-MM-DD",
      "description": "Transaction description",
      "amount": 1234.56,
      "category": "income" | "expense" | "housing" | "one-time",
      "flagged": true/false,
      "flagReason": "Luxury dining - $500 at upscale restaurant" (only if flagged),
      "monthYear": "2024-08"
    }
  ],
  "monthlyBreakdown": [
    {
      "month": "2024-08",
      "income": 5000.00,
      "expenses": 2500.00,
      "netCashFlow": 2500.00,
      "transactionCount": 45
    }
  ],
  "totalIncome": 5000.00,
  "totalExpenses": 2500.00,
  "netCashFlow": 2500.00,
  "confidence": 0.85
}`;

    // Create a timeout promise for the main analysis call
    const ANALYSIS_TIMEOUT_MS = 120000; // 120 seconds
    const analysisTimeoutPromise = new Promise<never>((_, reject) => {
      setTimeout(() => {
        console.error(`‚è±Ô∏è  Timeout reached for main analysis (${ANALYSIS_TIMEOUT_MS / 1000}s)`);
        reject(new Error(`Transaction analysis timed out after ${ANALYSIS_TIMEOUT_MS / 1000} seconds`));
      }, ANALYSIS_TIMEOUT_MS);
    });

    // Create the main analysis API call promise using configured model
    const analysisApiCallPromise = openai.chat.completions.create({
      model: VISION_MODEL,
      messages: [
        {
          role: 'system',
          content: 'You are a financial analyst specialized in cash flow analysis. Always respond with valid JSON.',
        },
        {
          role: 'user',
          content: prompt,
        },
      ],
      response_format: { type: 'json_object' },
      temperature: 0.1,
      max_tokens: 8000, // GPT-4o uses max_tokens
    }, {
      timeout: ANALYSIS_TIMEOUT_MS, // SDK timeout as backup
    });

    console.log(`üèÅ Racing main analysis against ${ANALYSIS_TIMEOUT_MS / 1000}s timeout...`);
    // Race the API call against the timeout
    const response = await Promise.race([analysisApiCallPromise, analysisTimeoutPromise]);
    console.log('‚úÖ AI analysis completed successfully');

    const result = JSON.parse(response.choices[0]?.message?.content || '{}');

    // Clean up uploaded files after processing
    for (const file of files) {
      try {
        await fs.unlink(file.path);
      } catch (error) {
        console.error(`Error deleting file ${file.path}:`, error);
      }
    }

    // Calculate average monthly balance (net cash flow that can offset principal)
    const averageMonthlyBalance = Math.max(0, result.netCashFlow);

    // Extract flagged transactions for review
    const flaggedTransactions = (result.transactions || []).filter((t: any) => t.flagged === true);

    console.log('üìà Analysis Results:');
    console.log(`  ‚úì Total transactions: ${result.transactions?.length || 0}`);
    console.log(`  ‚úì Flagged for review: ${flaggedTransactions.length}`);
    console.log(`  ‚úì Monthly deposits: $${result.totalIncome || 0}`);
    console.log(`  ‚úì Monthly expenses: $${result.totalExpenses || 0}`);
    console.log(`  ‚úì Net cash flow: $${result.netCashFlow || 0}`);
    console.log(`  ‚úì Confidence: ${((result.confidence || 0) * 100).toFixed(0)}%`);

    return {
      totalIncome: result.totalIncome || 0,
      totalExpenses: result.totalExpenses || 0,
      netCashFlow: result.netCashFlow || 0,
      averageMonthlyBalance,
      transactions: result.transactions || [],
      monthlyBreakdown: result.monthlyBreakdown || [],
      flaggedTransactions,
      confidence: result.confidence || 0.7,
    };
  } catch (error) {
    console.error('Error in analyzeStatements:', error);
    throw new Error(`Failed to analyze bank statements: ${error instanceof Error ? error.message : 'Unknown error'}`);
  }
}
